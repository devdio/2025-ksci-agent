{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e96093e-1035-4014-9cfd-fb65fa8bdb08",
   "metadata": {},
   "source": [
    "# SWAM Researcher\n",
    "\n",
    "https://github.com/langchain-ai/langgraph-swarm-py/tree/140fb07bcbd5e069ef716c6246a87cc00439b4a4/examples/research/src/agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f537a4ac-2c3b-4149-a798-8f95a778c6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qU langchain-mcp-adapters langgraph \"langchain[anthropic]\" \"langchain[openai]\" langgraph-swarm httpx markdownify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f1a702d6-590c-4d1e-a695-d42efb0c053a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 환경 변수 확인\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# TAVILY_API_KEY= os.environ.get(\"TAVILY_API_KEY\")\n",
    "# print(TAVILY_API_KEY[:20])\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "_set_env(\"TAVILY_API_KEY\")\n",
    "_set_env(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cbc5299c-df45-4739-b25f-3c774f0b6102",
   "metadata": {},
   "outputs": [],
   "source": [
    "planner_prompt = \"\"\"\n",
    "<Task>\n",
    "You will help plan the steps to implement a LangGraph application based on the user's request. \n",
    "</Task>\n",
    "\n",
    "<Instructions>\n",
    "1. Reflect on the user's request and the project scope\n",
    "2. Use the fetch_doc tool to read this llms.txt file, which gives you access to the LangGraph documentation: {llms_txt}\n",
    "3. [IMPORTANT]: After reading the llms.txt file, ask the user for clarifications to help refine the project scope.\n",
    "4. Once you have a clear project scope based on the user's feedback, select the most relevant URLs from the llms.txt file to reference in order to implement the project.\n",
    "5. Then, produce a short summary with two markdown sections: \n",
    "- ## Scope: A short description that lays out the scope of the project with up to 5 bullet points\n",
    "- ## URLs: A list of the {num_urls} relevant URLs to reference in order to implement the project\n",
    "6. Finally, transfer to the research agent using the transfer_to_researcher_agent tool.\n",
    "</Instructions>\n",
    "\"\"\"\n",
    "\n",
    "researcher_prompt = \"\"\"\n",
    "<Task>\n",
    "You will implement the solution to the user's request. \n",
    "</Task>\n",
    "\n",
    "<Instructions>\n",
    "1. First, reflect of the project Scope as provided by the planner agent.\n",
    "2. Then, use the fetch_doc tool to fetch and read each URL in the list of URLs provided by the planner agent.\n",
    "3. Reflect on the information in the URLs.\n",
    "4. Think carefully.\n",
    "5. Implement the solution to the user's request using the information in the URLs.\n",
    "6. If you need further clarification or additional sources to implement the solution, then transfer to transfer_to_planner_agent.\n",
    "</Instructions>\n",
    "\n",
    "<Checklist> \n",
    "Check that your solution satisfies all bullet points in the project Scope.\n",
    "</Checklist>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0bc44eee-516c-4643-b68b-e82d07020301",
   "metadata": {},
   "outputs": [],
   "source": [
    "import httpx\n",
    "from markdownify import markdownify\n",
    "\n",
    "httpx_client = httpx.Client(follow_redirects=False, timeout=10)\n",
    "\n",
    "\n",
    "def print_stream(stream):\n",
    "    for ns, update in stream:\n",
    "        print(f\"Namespace '{ns}'\")\n",
    "        for node, node_updates in update.items():\n",
    "            if node_updates is None:\n",
    "                continue\n",
    "\n",
    "            if isinstance(node_updates, (dict, tuple)):\n",
    "                node_updates_list = [node_updates]\n",
    "            elif isinstance(node_updates, list):\n",
    "                node_updates_list = node_updates\n",
    "            else:\n",
    "                raise ValueError(node_updates)\n",
    "\n",
    "            for node_updates in node_updates_list:\n",
    "                print(f\"Update from node '{node}'\")\n",
    "                if isinstance(node_updates, tuple):\n",
    "                    print(node_updates)\n",
    "                    continue\n",
    "                messages_key = next(\n",
    "                    (k for k in node_updates.keys() if \"messages\" in k), None\n",
    "                )\n",
    "                if messages_key is not None:\n",
    "                    node_updates[messages_key][-1].pretty_print()\n",
    "                else:\n",
    "                    print(node_updates)\n",
    "\n",
    "        print(\"\\n\\n\")\n",
    "\n",
    "    print(\"\\n===\\n\")\n",
    "\n",
    "\n",
    "def fetch_doc(url: str) -> str:\n",
    "    \"\"\"Fetch a document from a URL and return the markdownified text.\n",
    "\n",
    "    Args:\n",
    "        url (str): The URL of the document to fetch.\n",
    "\n",
    "    Returns:\n",
    "        str: The markdownified text of the document.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = httpx_client.get(url, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        return markdownify(response.text)\n",
    "    except (httpx.HTTPStatusError, httpx.RequestError) as e:\n",
    "        return f\"Encountered an HTTP error: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4e21a938-09b4-4643-8a6f-817a9304c954",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Any, Optional\n",
    "\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class Configuration(BaseModel):\n",
    "    \"\"\"The configurable fields for the research assistant.\"\"\"\n",
    "\n",
    "    llms_txt: int = Field(\n",
    "        default=\"https://langchain-ai.github.io/langgraph/llms.txt\",\n",
    "        title=\"llms.txt URL\",\n",
    "        description=\"llms.txt URL to use for research\",\n",
    "    )\n",
    "\n",
    "    @classmethod\n",
    "    def from_runnable_config(\n",
    "        cls, config: Optional[RunnableConfig] = None\n",
    "    ) -> \"Configuration\":\n",
    "        \"\"\"Create a Configuration instance from a RunnableConfig.\"\"\"\n",
    "        configurable = (\n",
    "            config[\"configurable\"] if config and \"configurable\" in config else {}\n",
    "        )\n",
    "\n",
    "        # Get raw values from environment or config\n",
    "        raw_values: dict[str, Any] = {\n",
    "            name: os.environ.get(name.upper(), configurable.get(name))\n",
    "            for name in cls.model_fields.keys()\n",
    "        }\n",
    "\n",
    "        # Filter out None values\n",
    "        values = {k: v for k, v in raw_values.items() if v is not None}\n",
    "\n",
    "        return cls(**values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6bc95cbb-a907-430c-b50d-541771f6e025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langgraph_swarm import create_handoff_tool, create_swarm\n",
    "\n",
    "# Chat model (OpenAI)\n",
    "model = init_chat_model(\n",
    "    model=\"gpt-4o-mini\", \n",
    "    model_provider=\"openai\")\n",
    "\n",
    "# Reasoning model (OpenAI)\n",
    "model = init_chat_model(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    model_provider=\"openai\"\n",
    ")\n",
    "\n",
    "# Handoff tools\n",
    "transfer_to_planner_agent = create_handoff_tool(\n",
    "    agent_name=\"planner_agent\",\n",
    "    description=\"Transfer the user to the planner_agent for clarifying questions related to the user's request.\",\n",
    ")\n",
    "transfer_to_researcher_agent = create_handoff_tool(\n",
    "    agent_name=\"researcher_agent\",\n",
    "    description=\"Transfer the user to the researcher_agent to perform research and implement the solution to the user's request.\",\n",
    ")\n",
    "\n",
    "# LLMS.txt\n",
    "llms_txt = \"LangGraph:https://langchain-ai.github.io/langgraph/llms.txt\"\n",
    "num_urls = 3\n",
    "planner_prompt_formatted = planner_prompt.format(llms_txt=llms_txt, num_urls=num_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "23ece781-43ca-4675-bfb2-943b75b3e80e",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'StateGraph' object has no attribute 'schema'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 21\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# Swarm\u001b[39;00m\n\u001b[32m     20\u001b[39m checkpointer = InMemorySaver()\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m agent_swarm = \u001b[43mcreate_swarm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mplanner_agent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresearcher_agent\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_active_agent\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mplanner_agent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     23\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m app = agent_swarm.compile(checkpointer=checkpointer)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\ws\\2025-ksci-agent\\.venv\\Lib\\site-packages\\langgraph_swarm\\swarm.py:211\u001b[39m, in \u001b[36mcreate_swarm\u001b[39m\u001b[34m(agents, default_active_agent, state_schema, config_schema)\u001b[39m\n\u001b[32m    209\u001b[39m state_schema = _update_state_schema_agent_names(state_schema, agent_names)\n\u001b[32m    210\u001b[39m builder = StateGraph(state_schema, config_schema)\n\u001b[32m--> \u001b[39m\u001b[32m211\u001b[39m \u001b[43madd_active_agent_router\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    212\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbuilder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    213\u001b[39m \u001b[43m    \u001b[49m\u001b[43mroute_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43magent_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    214\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdefault_active_agent\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdefault_active_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    215\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m agent \u001b[38;5;129;01min\u001b[39;00m agents:\n\u001b[32m    217\u001b[39m     builder.add_node(\n\u001b[32m    218\u001b[39m         agent.name,\n\u001b[32m    219\u001b[39m         agent,\n\u001b[32m    220\u001b[39m         destinations=\u001b[38;5;28mtuple\u001b[39m(get_handoff_destinations(agent)),\n\u001b[32m    221\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\ws\\2025-ksci-agent\\.venv\\Lib\\site-packages\\langgraph_swarm\\swarm.py:124\u001b[39m, in \u001b[36madd_active_agent_router\u001b[39m\u001b[34m(builder, route_to, default_active_agent)\u001b[39m\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34madd_active_agent_router\u001b[39m(\n\u001b[32m     57\u001b[39m     builder: StateGraph,\n\u001b[32m     58\u001b[39m     *,\n\u001b[32m     59\u001b[39m     route_to: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m],\n\u001b[32m     60\u001b[39m     default_active_agent: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m     61\u001b[39m ) -> StateGraph:\n\u001b[32m     62\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Add a router to the currently active agent to the StateGraph.\u001b[39;00m\n\u001b[32m     63\u001b[39m \n\u001b[32m     64\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    122\u001b[39m \u001b[33;03m        ```\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m     channels = builder.schemas[\u001b[43mbuilder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mschema\u001b[49m]\n\u001b[32m    125\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mactive_agent\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m channels:\n\u001b[32m    126\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mMissing required key \u001b[39m\u001b[33m'\u001b[39m\u001b[33mactive_agent\u001b[39m\u001b[33m'\u001b[39m\u001b[33m in in builder\u001b[39m\u001b[33m'\u001b[39m\u001b[33ms state_schema\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: 'StateGraph' object has no attribute 'schema'"
     ]
    }
   ],
   "source": [
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "# Planner agent\n",
    "planner_agent = create_react_agent(\n",
    "    model,\n",
    "    prompt=planner_prompt_formatted,\n",
    "    tools=[fetch_doc, transfer_to_researcher_agent],\n",
    "    name=\"planner_agent\",\n",
    ")\n",
    "\n",
    "# Researcher agent\n",
    "researcher_agent = create_react_agent(\n",
    "    model,\n",
    "    prompt=researcher_prompt,\n",
    "    tools=[fetch_doc, transfer_to_planner_agent],\n",
    "    name=\"researcher_agent\",\n",
    ")\n",
    "\n",
    "# Swarm\n",
    "checkpointer = InMemorySaver()\n",
    "agent_swarm = create_swarm(\n",
    "    [planner_agent, researcher_agent], default_active_agent=\"planner_agent\"\n",
    ")\n",
    "app = agent_swarm.compile(checkpointer=checkpointer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164628c5-d03b-43c7-a4e8-165bf382edbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9afc69-4aca-4e4f-ba5d-fbd44a681791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "request = \"Create a LangGraph application that is a prompt chain: it takes a topic from a user, generates a joke, and checks if the joke has a punchline.\"\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "print_stream(\n",
    "    app.stream(\n",
    "        {\"messages\": [{\"role\": \"user\", \"content\": request}]}, config, subgraphs=True\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabe47a3-d208-4ba8-a40d-95a619c60f2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4f5c27-358f-4bc1-b393-3ce60e598699",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4e89b1-2b07-4b3a-a2d3-9d0a785f1cf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b0b56e-16a1-4b11-abf5-e36506501a74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f024dae9-970a-45b6-9082-6ff031cf2f3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
